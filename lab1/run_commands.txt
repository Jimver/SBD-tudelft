# Run before every code change
sbt package

# Docker commands
docker run -it --rm -v "`pwd`":/io -v "`pwd`"/spark-events:/spark-events \
spark-submit --class RDD \
target/scala-2.11/lab-1_2.11-1.0.jar

docker run -it --rm -v "`pwd`":/io -v "`pwd`"/spark-events:/spark-events \
spark-submit --class Dataset \
target/scala-2.11/lab-1_2.11-1.0.jar

# Local run commands
spark-submit --class "RDD" target/scala-2.11/lab-1_2.11-1.0.jar
spark-submit --class "Dataset" target/scala-2.11/lab-1_2.11-1.0.jar

# AWS cluster creation
aws emr create-cluster --termination-protected --applications Name=Hadoop Name=Hive Name=Pig Name=Hue Name=Spark Name=Ganglia --ec2-attributes '{"KeyName":"windows-laptop","InstanceProfile":"EMR_EC2_DefaultRole","SubnetId":"subnet-1fcf7153","EmrManagedSlaveSecurityGroup":"sg-0c2f54ccebd247787","EmrManagedMasterSecurityGroup":"sg-0629772a9e5712b31"}' --release-label emr-5.27.0 --log-uri 's3n://aws-logs-267689942826-us-east-2/elasticmapreduce/' --steps '[{"Args":["spark-submit","--deploy-mode","cluster","--class","Dataset","s3://jimver-bigdata/lab-1_2.11-1.0.jar"],"Type":"CUSTOM_JAR","ActionOnFailure":"TERMINATE_CLUSTER","Jar":"command-runner.jar","Properties":"","Name":"Spark application"}]' --instance-groups '[{"InstanceCount":1,"BidPrice":"OnDemandPrice","EbsConfiguration":{"EbsBlockDeviceConfigs":[{"VolumeSpecification":{"SizeInGB":100,"VolumeType":"gp2"},"VolumesPerInstance":1}],"EbsOptimized":true},"InstanceGroupType":"MASTER","InstanceType":"c4.8xlarge","Name":"Master - 1"},{"InstanceCount":19,"BidPrice":"OnDemandPrice","EbsConfiguration":{"EbsBlockDeviceConfigs":[{"VolumeSpecification":{"SizeInGB":100,"VolumeType":"gp2"},"VolumesPerInstance":1}],"EbsOptimized":true},"InstanceGroupType":"CORE","InstanceType":"c4.8xlarge","Name":"Core - 2"}]' --auto-terminate --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 10 --service-role EMR_DefaultRole --enable-debugging --name 'Dataset_cluster_2' --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region us-east-2
